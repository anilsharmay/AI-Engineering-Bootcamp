# YouTube RAG Architecture Diagram

```mermaid
graph TB
    %% Input Layer
    YT_URL["ğŸ¥ YouTube URL<br/>https://youtube.com/watch?v=..."]
    
    %% YouTube Transcript Processing
    YT_LOADER["ğŸ“ YouTubeTranscriptLoader<br/>â€¢ Extract video ID<br/>â€¢ Handle URL patterns<br/>â€¢ Error handling"]
    YT_API["ğŸ”— YouTube Transcript API<br/>â€¢ Fetch transcript segments<br/>â€¢ Language support<br/>â€¢ Error handling"]
    
    %% Text Processing
    TRANSCRIPT["ğŸ“„ Raw Transcript<br/>â€¢ Full text content<br/>â€¢ Segment metadata<br/>â€¢ Video metadata"]
    DOC_METADATA["ğŸ“‹ Document with Metadata<br/>â€¢ get_document_with_metadata()<br/>â€¢ Combined text + metadata<br/>â€¢ Ready for chunking"]
    SPLITTER["âœ‚ï¸ CharacterTextSplitter<br/>â€¢ Chunk size: 500<br/>â€¢ Overlap: 100<br/>â€¢ Preserve context"]
    CHUNKS["ğŸ“¦ Text Chunks<br/>â€¢ Multiple segments<br/>â€¢ Basic chunks only<br/>â€¢ No metadata yet"]
    CHUNK_METADATA["ğŸ·ï¸ Chunk Metadata Creation<br/>â€¢ Inherit parent metadata<br/>â€¢ Add chunk_id, chunk_length<br/>â€¢ Create chunks_with_metadata"]
    CHUNKS_WITH_META["ğŸ“¦ Chunks with Metadata<br/>â€¢ Text + metadata combined<br/>â€¢ Ready for embedding<br/>â€¢ Full context preserved"]
    
    %% Vector Database
    EMBEDDING["ğŸ§  EmbeddingModel<br/>â€¢ OpenAI text-embedding-3-small<br/>â€¢ Async processing<br/>â€¢ Vector generation"]
    VECTOR_DB["ğŸ—„ï¸ VectorDatabase<br/>â€¢ Store vectors + metadata<br/>â€¢ Cosine similarity<br/>â€¢ Metadata retrieval"]
    
    %% RAG Pipeline
    USER_QUERY["â“ User Query<br/>â€¢ Natural language question<br/>â€¢ About video content"]
    RETRIEVAL["ğŸ” Similarity Search<br/>â€¢ search_by_text(query, k=3, include_metadata=True)<br/>â€¢ Most relevant chunks<br/>â€¢ Similarity scores"]
    CONTEXT["ğŸ“‹ Retrieved Context<br/>â€¢ Relevant chunks<br/>â€¢ Video metadata<br/>â€¢ Similarity scores"]
    
    %% LLM Processing
    PROMPTS["ğŸ“ Prompt Engineering<br/>â€¢ System prompt<br/>â€¢ User prompt with context<br/>â€¢ YouTube-specific instructions"]
    LLM["ğŸ¤– ChatOpenAI<br/>â€¢ GPT model<br/>â€¢ Context-aware responses<br/>â€¢ Video-specific answers"]
    
    %% Output
    RESPONSE["ğŸ’¬ Final Response<br/>â€¢ Markdown formatted<br/>â€¢ Video context included<br/>â€¢ Pretty display"]
    
    %% Error Handling
    ERROR_HANDLING["âš ï¸ Error Handling<br/>â€¢ No transcript found<br/>â€¢ Transcripts disabled<br/>â€¢ Video unavailable<br/>â€¢ API errors"]
    
    %% Flow connections
    YT_URL --> YT_LOADER
    YT_LOADER --> YT_API
    YT_API --> TRANSCRIPT
    YT_API --> ERROR_HANDLING
    
    TRANSCRIPT --> DOC_METADATA
    DOC_METADATA --> SPLITTER
    SPLITTER --> CHUNKS
    CHUNKS --> CHUNK_METADATA
    CHUNK_METADATA --> CHUNKS_WITH_META
    
    CHUNKS_WITH_META --> EMBEDDING
    EMBEDDING --> VECTOR_DB
    
    USER_QUERY --> RETRIEVAL
    VECTOR_DB --> RETRIEVAL
    RETRIEVAL --> CONTEXT
    
    CONTEXT --> PROMPTS
    PROMPTS --> LLM
    LLM --> RESPONSE
    
    %% Styling
    classDef inputClass fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef processClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef storageClass fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
    classDef outputClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef errorClass fill:#ffebee,stroke:#c62828,stroke-width:2px
    
    class YT_URL,USER_QUERY inputClass
    class YT_LOADER,YT_API,SPLITTER,CHUNK_METADATA,EMBEDDING,RETRIEVAL,PROMPTS,LLM processClass
    class TRANSCRIPT,DOC_METADATA,CHUNKS,CHUNKS_WITH_META,VECTOR_DB,CONTEXT storageClass
    class RESPONSE outputClass
    class ERROR_HANDLING errorClass
```

## Key Components

### 1. **YouTube Transcript Ingestion**
- **YouTubeTranscriptLoader**: Extracts video ID from various YouTube URL formats
- **YouTube Transcript API**: Fetches transcript segments with error handling
- **Error Handling**: Manages cases where transcripts are unavailable

### 2. **Text Processing Pipeline**
- **CharacterTextSplitter**: Chunks transcript into manageable pieces
- **Metadata Preservation**: Maintains video information throughout processing

### 3. **Vector Database**
- **EmbeddingModel**: Converts text chunks to vector embeddings
- **VectorDatabase**: Stores vectors with associated metadata
- **Similarity Search**: Uses `search_by_text(query, k=3, include_metadata=True)` to retrieve most relevant chunks

### 4. **RAG Pipeline**
- **YouTubeRAGPipeline**: Specialized pipeline for YouTube content
- **Prompt Engineering**: YouTube-aware system and user prompts
- **Context Integration**: Combines retrieved chunks with video metadata

### 5. **Response Generation**
- **ChatOpenAI**: Generates context-aware responses
- **Pretty Display**: Markdown-formatted output with video context

## Data Flow

1. **Input**: YouTube URL â†’ Video ID extraction
2. **Ingestion**: Transcript API â†’ Raw transcript text
3. **Document Preparation**: Raw transcript â†’ Document with metadata
4. **Text Processing**: Document â†’ Text splitting â†’ Basic chunks
5. **Metadata Creation**: Basic chunks â†’ Chunks with metadata
6. **Embedding**: Chunks with metadata â†’ Vector embeddings
7. **Storage**: Vectors + metadata â†’ Vector database
8. **Query**: User question â†’ search_by_text(query, k=3, include_metadata=True)
9. **Retrieval**: Relevant chunks + metadata â†’ Context
10. **Generation**: Context + prompts â†’ LLM response
11. **Output**: Formatted response with video context
